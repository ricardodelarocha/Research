# Free Jailbreaks in LLMs

This work contains sensitive material, but its purpose is purely didactic. All experiments were performed responsibly in controlled environments, with no intent of malicious use. Readers are strongly discouraged from replicating these actions outside academic or ethical research contexts.

## About this repository
This repository gathers the appendices of **Exploring Jailbreaks in Large Language Models: An Experimental Analysis of Safety Barriers** paper.  

## Contents
- (under construction)

## Backup
- (under construction)

## Notes
These materials are supplementary to the main paper and are provided for transparency and replication purposes.
